{"key_paths": ["log_dir_thesis/csvs/testreward", "log_dir_thesis/csvs/testreward", "log_dir_thesis/csvs/testreward", "log_dir_thesis/csvs/testreward", "log_dir_thesis/csvs/testreward", "log_dir_thesis/csvs/avg_cost"], "y_df_labels": ["test/reward", "test/reward", "test/reward", "test/reward", "test/reward", "avg_cost"], "invert_y": [false, false, false, false, false, true], "x_df_label": "Steps", "y_display_label": "average solution length", "x_display_label": "number of samples trained", "run_names": ["run_134__20220502T041222", "run_131__20220501T150459", "run_168__20220501T150725_20220501T161918", "run_132__20220502T021254", "run_133__20220501T150505", "run_k36__20220502T180034"], "line_names": ["DQN", "PG", "SAC", "A2C", "PPO", "Kool et al."], "plot_filename": "op_final_trainings", "legend_title": "Algorithm", "is_reward_plot": false, "y_type": "linear"}